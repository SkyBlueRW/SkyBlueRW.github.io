#

## The Practical Side of Black-Litterman and More


- [Introduction](#introduction)
- [The Practical Side of Black-Litterman](#practical)
  - [The Black Litterman Tau](#subparagraph1)
  - [The Subjective Omega](#subparagraph2)
- [More on Expected Return Forecast](#more)
  - ["The more the better?"](#subparagraph3)
  - [More on Black-Litterman](#subparagraph4)
- [Reference](#ref)

### Introduction <a name="introduction"></a>

Forecasting expected return is a rewarding yet hallenging endeavor. One shot to tilt the odds in our favor in this battle is probably to take into account as much relavant information as possible. In such cases, a reliable method to weave together these information of distinct categories and forms becomes quite crutial. 

The Black-Litterman model provides one such dependable solution. As discussed in the previous blog ([Anchor Your Forecast the Bayesian Way](https://skybluerw.github.io/2023/07/27/anchor-forecast-bayesian.html)), the Bayesian franmework underlying the model takes all relavant information/forecast on expected return as variables with uncertainties and combined them in a Bayesian way to account for uncertainties.

Black-Litterman serves as an excellent starting point for our exploration of refinement on expected return forecast, while there's still a vast landscape to explore ahead!! In this blog, we'll delve deeper into the practical applications of the Black-Litterman model and conclude with a casual chat on the effort to incorporate multiple forecasts and its connection with Black-Litterman model.

### The Practical Side of Black-Litterman <a name="practical"></a>

![BL](https://raw.githubusercontent.com/SkyBlueRW/SkyBlueRW.github.io/main/_posts/asset/bl.png)

Firstly, let's continue our discussion on the Black-Litterman model from the previous blog ([Anchor Your Forecast the Bayesian Way](https://skybluerw.github.io/2023/07/27/anchor-forecast-bayesian.html)). Without much assumptions placed so far, we got a refined forecast that combines all original forecast/information in the form of posterior.

$$
\begin{aligned}
\mu^{\star} &= (\Sigma_{\pi} + P^T\Omega^{-1}P)^{-1}(\Sigma_{\pi}^{-1} \pi + P^T\Omega^{-1}Q) \\
M &= (\Sigma_{\pi} + P^T\Omega^{-1}P)^{-1}
\end{aligned}
$$

This is a general framework, with which, we are free to feed in all kinds of investment view (prior and likelihood) within the Gaussian world. While such a general model usually comes with heavy requirements on estimation in application. For the two matrix measuring uncertainty ($$\Sigma_{\pi}$$ and $$\Omega$$) alone, we have $$N^2 + K^2$$ parameters to estimate. (N and K refers to number of securities in the universe and number of original forecast respectively). 

To faciliate the estimation and reduce the model risk originated from such large number of parameters, a lot of techniques with further restriction upon the Gassuan assumption are applied in application. Let's look into some of these techniques that help to put the Bayesian framwork in application.


#### The Black Litterman Tau <a name="subparagraph1"></a>

One additional authentic assumption that Black & Litterman themselves make is that the covariance matrix measuring uncertainty around prior ($$\Sigma_{\pi}$$) is proportional to return covariance matrix ($$\Sigma_{\pi} = \tau \Sigma$$). Remeber that, for good reasons, the prior is extracted from reverse optimization wihout clearly defined uncertainty. While this additional assumption instantly free us from $$N^2$$ vague estimations.

Obviously it is not the 'correct and accurate' assumption, while it does pick some key points from the full picture and greatly reduce the tension on estimation. Higher volatility in security return generally means more difficulty in the estimation of expected return. With this assumption in place, we get the standard Black-Litterman estimation in the following form.

$$
\begin{aligned}
\mu^{\star} &= (\tau \Sigma + P^T\Omega^{-1}P)^{-1}((\tau \Sigma)^{-1} \pi + P^T\Omega^{-1}Q) \\
M &= (\tau \Sigma + P^T\Omega^{-1}P)^{-1}
\end{aligned}
$$

The scaling factor $$\tau$$ is all required to determine the unceratainty around prior now. Generally, $$\tau$$ is assigned heuristically with a small value close to 0 as "uncertainty in the mean is much smaller than the uncertainty in the return itself" (Black & Litterman (1992)). The argument is consistent with other methods proposed to set $$\tau$$. Either to take the uncertainty as sampling error ($$\tau = \dfrac{1}{T}$$) or imply it from holding in risky asset in reference portfolio ($$\tau = \dfrac{1}{w_{risky}} - 1$$) generally lead to $$\tau$$ at the range within 0 and 0.1. [Walters (2013)](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1701467) provides a very comprehensive review about the parameter $$\tau$$.


#### The Subjective Omega <a name="subparagraph2"></a>

With uncertainty around prior set with $$\tau$$, let's take a more detailed look into the determination of uncertainty around other investment views. We would want to be able to include all kinds of investment views.

It is rather intuitive to set the uncertainty around investment views generated from statistical model. Forecasting errors (I.E. residual variance in a regression) are generally available to fit in the shoes easily. What's not that intuitive is with investment views not generated in a quantitative way without forecast error available (I.E. subjective judgement). Additional efforts would be required to incorporate such kinds of investment views.

Similarly to Black & Litterman's assumption on prior uncertainty, we can assume that uncertainty around other investment views is proportional to return variance as well. After all, it's the comparison between uncertainty that matters. For a subjective investment view k expressed as a linear portfolio ($$p_k$$), we can assume the uncertainty is scaled on the portfolio variance. Now the question turn to the setting of $$\alpha$$.

$$
\begin{aligned}
\omega_k &= \alpha P_k \Sigma P_k^T
\end{aligned}
$$

**Idozek Implied Confidence Level**

Idozek(2007) proposed a very intuitive way to infer $$\alpha$$ from percentage of confidence defined in terms of desired active deviation. 

Depending on our confidence of one particular investment view k, our refined posterior mean range between $$\mu^{\star}_{0}$$ (in case of 0 confidence in the view/ $$\alpha \to \infty$$) and $$\mu^{\star}_{100}$$ (in case of absolute confidence in the view $$\alpha = 0$$). Correspondingly, the most confident portfolio $$x^{\star}_{100}$$ and most conservative portfolio $$x^{\star}_0$$.

$$
\begin{aligned}
\mu^{\star} &= \pi + \Sigma_{\pi}P_k^T(\Omega + P_k\Sigma_{\pi}P_k^T)^{-1} (Q-P_k\pi) \\
\mu^{\star}_{100} &= \pi + \tau\Sigma P_k^T (P_k\tau \Sigma P_k^T)^{-1}(Q - P_k\pi)\\
\mu^{\star}_0 &= \pi \\
x^{\star}_{100} &= (\lambda \Sigma)^{-1} \mu^{\star}_{100}\\
x^{\star}_0 &= (\lambda \Sigma)^{-1} \pi = x_0\\
\end{aligned}
$$

A confidence level (0% ~ 100%) can be defined in terms of the desired position ($$\hat{x}$$) between the two portfolios of $$x^{\star}_0$$ and $$x^{\star}_{100}$$.    

$$
\begin{aligned}
confidence &= \dfrac{\hat{x} - x^{\star}_0}{x^{\star}_{100} - x^{\star}_0} \\
\hat{x} &= x^{\star}_0 + confidence * (x^{\star}_{100} - x^{\star}_0) \\
\end{aligned}
$$

This is actually quite an intuive and consistent way to express confidence. For one hand, we are enabled the flexibility to express our confidence in percentage. For the other hand, this percentage of confidence is **linearly proportional to our active weight and risk**. As we increase our confidence from 0 to 100%, the active weight increases linearly from $$x^{\star}_0$$ to $$x^{\star}_{100}$$ so does the active risk.

Now things become much simpler. We turn our confidence on one investment view to a consistent portfolio. It's not that hard to infer the corresponding $$\omega$$ from it. Walters (2007) provides an analytical solution for this step leads to quite simplified results.

$$
\begin{aligned}
\dfrac{1}{1 + \alpha} &= \dfrac{\hat{x} - x^{\star}_0}{x^{\star}_{100} - x^{\star}_0} = confidence \\
&\downarrow \\
\alpha &= \dfrac{1 - confidence}{confidence} \\ 
\omega_k & = \alpha p_k \Sigma p_k^T \\
\end{aligned}
$$

For all investment views lacking clear defined uncertainty, we can iterate this process and get its uncertainty $$\omega$$ respectively. With the Idozek implied confidence level technique, the BL can expand to a lot more use cases to incorporate all kinds of investment views as long as we do have some judgement on the uncertainty.

**Haesen, Hallerbach, Markwat & Molenaar tau/alpha ratio**

For the use case of asset allocation, Haesen, Hallerbach, Markwat & Molenaar (2017) proposed to assume the availability of only absolute view on all securities and directly define the ratio of $$\dfrac{\tau}{\alpha}$$ rather then define them separately. With this additional restriction, P becomes an identity matrix leads to significant simplification of the refinement.

$$
\begin{aligned}
P &= I_N \\
&\downarrow \\
\mu^{\star} &= (1 + \dfrac{\tau}{\alpha})^{-1} (\pi + \dfrac{\tau}{\alpha}Q) \\
M &= (\tau^{-1} + \alpha^{-1}) \Sigma
\end{aligned}
$$

Now what matters in the mix of investment views is the ratio $$\dfrac{\tau}{\alpha}$$. The weights placed on the investment views is **linearly proportional to the ratio**.

$$
\begin{aligned}
\alpha \to 0 (\dfrac{\tau}{\alpha} \to \infty)\\
\mu^{\star} &= Q\\
M &\to 0\\
\alpha = \tau  (\dfrac{\tau}{\alpha} = \dfrac{1}{2})\\
\mu^{\star} &= \dfrac{1}{2} (Q + \pi) \\
M &= \dfrac{1}{2} \tau \Sigma \\
\alpha \to \infty (\dfrac{\tau}{\alpha} \to 0)\\
\mu^{\star} &= \pi \\
M &= \tau \Sigma \\
\end{aligned}
$$

Before closing the mark, it is worth to mention that once we apply this structure of $$\alpha$$ and $$\tau$$ to define the uncertainty around prior and likelihood, the ratio of $$\dfrac{\tau}{\alpha}$$ alone is sufficient to define our posterior mean ($$\mu^{\star}$$). It is the existence of posterior variance (M) that requires the seprate estimation of $$\tau$$ and $$\alpha$$.

$$
\begin{aligned}
\mu^{\star} &= (\tau \Sigma + P^T\Omega^{-1}P)^{-1}((\tau \Sigma)^{-1} \pi + P^T\Omega^{-1}Q) \\
 &= \pi + \tau \Sigma P^T(\alpha P\Sigma P^T + \tau P\Sigma P^T)^{-1} (Q-P\pi) \\
&= \pi + \Sigma P^T (\dfrac{\alpha}{\tau} P\Sigma P^T +  P\Sigma P^T)^{-1} (Q-P\pi)\\
M &= (\tau \Sigma + P^T\Omega^{-1}P)^{-1} \\ 
& = (1 + \tau)\Sigma - \tau^2\Sigma P^T (\tau P \Sigma P^T + \Omega)^{-1}P \Sigma
\end{aligned}
$$

Generally we care more about the posterior mean than to the posterior variance. That's probably the rationale behind lots of modifications on Black-Litterman out there only focusing on posterior mean with $$\dfrac{\tau}{\alpha}$$ only. Such a treatment is no longer a full scaled Bayesian framework while it still carries lots of merits prevsiously mentioned. 



### More on Expected Return Forecast <a name="more"></a>

The techniques discussed above should prepare us reasonably in putting Black-Litterman model in real world application. Wihout doubt, Black-Litterman (or more generally the Bayesian framework underlying) is a powerful and intuitive tool. It enables us to start from the reference portfolio and combine more forecasts by deviating. 

At this point before we call an end on this blog. I feel it deserves a bit more brainstorm on the idea of combining more information to refine forecast on expected return and BLack-Litterman's role in this effort at the first places.


#### "The more the better?" <a name="subparagraph3"></a>

To me, combining multiple forecasts for refined expected return forecast is a reasonable effort from various perspectives. 


**The Finance Perspective**

There are lots and lots of differnt kinds of factors impacting expected returns of various horizons on different securities. Due to all kinds restriction in modeling and data, there is not yet a unifed model or framework to take them all in once. This question of expected return forecast is generally 'divided and conqued'. Efforts are generally made to model the expected return of a specific horizon on a subset of securities with a parsimonious set of factors. 

For example, standing on the horizon of tens of years, fundamental variables such as population and technology are usually considered crutial to forecast long term return on asset classes. Zooming in a little bit on the horizon of a few years, business cycle relavant variables such as consumption, production are used a lot to forecast return on asset classes, sectors and more. Contuiting going down to shorther horizon, company characteristics are widely used for forecast of equity. 

If forecasting expected return itself is a big question. We have models regionally. It makes sense to combine some of these mdoels on a fraction of the full picture for a more copmprehensive review.

**The Data Science Perspective**

stacking to aggreate relatively weak  models to create a stronger meta model. As the philosophy and the old saying "Unity is strength"

https://towardsdatascience.com/ensemble-methods-bagging-boosting-and-stacking-c9214a10a205
https://www.analyticsvidhya.com/blog/2023/01/ensemble-learning-methods-bagging-boosting-and-stacking/#h-steps-of-bagging
Of the two side bias and variance. a lot of time remain the bigger concern variance. 

#### More on Black-Litterman <a name="subparagraph4"></a>


Now turn back to Black-Litterman model and the associated Bayesian framework again. At its core, it takes various expected return forecast likely generated from different models and combine them into one refined new estimation. In this process, although named and used differently, the difference between the forecast in terms of prior and the forecast in terms of likelihood is smaller than it seems. They are all taken as forecast on expected returns with uncertainties. 

In my view, what make the pior stand out from all expected forecast are two folds. For one hand, the prior forecast do have opnion on every security within the universe, which build the base line for other partial forecasts. 

a lot of factor impacting expected return. looking into different horizon asset type lead to different key drivers. hard to get an integrated model. divide and conquer is a solution. 




### Reference <a name="ref"></a>

- Walters (2013): The Factor Tau in the Black-Litterman Model
- Walters (2007): The Black-Litterman Model in Details
- Idzorek (2007): A step-by-step guide to the Black-Litterman model
- Haesen, Hallerbach, Markwat & Molenaar (2017): Enhancing Risk Parity By Including Views
